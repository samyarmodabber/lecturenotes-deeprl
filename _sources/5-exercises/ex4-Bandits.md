# Bandits (part 1)

The goal of this exercise is to implement simple action selection mechanisms for the n-armed bandit:

* Greedy action selection
* $\epsilon$-greedy action selection
* Softmax action selection

**Presentation**

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/pYxphhdmrD4" frameborder="0" allowfullscreen></iframe>
</div>

**Commented solution**

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/x60ffQE59Eo" frameborder="0" allowfullscreen></iframe>
</div>
